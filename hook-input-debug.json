{"session_id":"8bb2c53a-1df0-4ab6-903a-35959f8180e4","transcript_path":"C:\\Users\\1\\.claude\\projects\\C--Users-1-Documents-GitHub-MAGRAY\\8bb2c53a-1df0-4ab6-903a-35959f8180e4.jsonl","cwd":"C:\\Users\\1\\Documents\\GitHub\\MAGRAY","permission_mode":"bypassPermissions","hook_event_name":"PostToolUse","tool_name":"Edit","tool_input":{"file_path":"C:\\Users\\1\\Documents\\GitHub\\MAGRAY\\src-tauri\\src\\project_manager.rs","old_string":"impl Default for ProjectSandboxConfig {\n    fn default() -> Self {\n        let mut allowed_dirs = Vec::new();\n        \n        // Add user's home directory subdirectories\n        if let Some(home) = dirs::home_dir() {\n            allowed_dirs.push(home.join(\"Documents\"));\n            allowed_dirs.push(home.join(\"Projects\"));\n            allowed_dirs.push(home.join(\"workspace\"));\n            allowed_dirs.push(home.join(\"dev\"));\n            allowed_dirs.push(home.join(\"src\"));\n            allowed_dirs.push(home.join(\"Desktop\"));\n        }\n        \n        // Add current working directory if not in system location\n        if let Ok(cwd) = std::env::current_dir() {\n            let cwd_str = cwd.to_string_lossy().to_lowercase();\n            #[cfg(target_os = \"windows\")]\n            let is_system = cwd_str.starts_with(\"c:\\\\windows\") || cwd_str.starts_with(\"c:\\\\program\");\n            #[cfg(not(target_os = \"windows\"))]\n            let is_system = cwd_str.starts_with(\"/etc\") || cwd_str.starts_with(\"/sys\");\n            \n            if !is_system {\n                allowed_dirs.push(cwd);\n            }\n        }\n        \n        Self {\n            allowed_directories: allowed_dirs,\n            max_project_size: 10 * 1024 * 1024 * 1024, // 10GB\n            max_file_size: 100 * 1024 * 1024, // 100MB\n            max_file_count: 100_000,\n        }\n    }\n}","new_string":"impl Default for ProjectSandboxConfig {\n    fn default() -> Self {\n        let mut allowed_dirs = Vec::new();\n        \n        // Add user's home directory subdirectories with validation\n        if let Some(home) = dirs::home_dir() {\n            // List of subdirectories to allow under home\n            let subdirs = [\n                \"Documents\",\n                \"Projects\", \n                \"workspace\",\n                \"dev\",\n                \"src\",\n                \"Desktop\",\n                \"GitHub\",\n                \"repos\",\n                \"code\",\n            ];\n            \n            for subdir in &subdirs {\n                let path = home.join(subdir);\n                // Only add if directory exists and can be canonicalized\n                if path.exists() && path.is_dir() {\n                    if let Ok(canonical) = path.canonicalize() {\n                        // Verify it's still under home after canonicalization (no symlink escape)\n                        if let Ok(canonical_home) = home.canonicalize() {\n                            if canonical.starts_with(&canonical_home) {\n                                allowed_dirs.push(canonical);\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        \n        // Add current working directory if safe\n        if let Ok(cwd) = std::env::current_dir() {\n            if let Ok(canonical_cwd) = cwd.canonicalize() {\n                let cwd_str = canonical_cwd.to_string_lossy().to_lowercase();\n                \n                // Block system directories across all platforms\n                let is_system = \n                    // Windows system directories\n                    cwd_str.starts_with(\"c:\\\\windows\") || \n                    cwd_str.starts_with(\"c:\\\\program files\") ||\n                    cwd_str.starts_with(\"c:\\\\programdata\") ||\n                    // Unix/Linux system directories\n                    cwd_str.starts_with(\"/etc\") || \n                    cwd_str.starts_with(\"/sys\") ||\n                    cwd_str.starts_with(\"/proc\") ||\n                    cwd_str.starts_with(\"/dev\") ||\n                    cwd_str.starts_with(\"/boot\") ||\n                    cwd_str.starts_with(\"/bin\") ||\n                    cwd_str.starts_with(\"/sbin\") ||\n                    cwd_str.starts_with(\"/lib\") ||\n                    cwd_str.starts_with(\"/usr/bin\") ||\n                    cwd_str.starts_with(\"/usr/sbin\") ||\n                    // macOS system directories\n                    cwd_str.starts_with(\"/system\") ||\n                    cwd_str.starts_with(\"/library\") ||\n                    cwd_str.starts_with(\"/private\");\n                \n                if !is_system {\n                    allowed_dirs.push(canonical_cwd);\n                }\n            }\n        }\n        \n        // Add temp directory for scratch projects (sandboxed)\n        if let Some(temp_dir) = dirs::data_local_dir() {\n            let atom_temp = temp_dir.join(\"atom-ide\").join(\"projects\");\n            // Create if doesn't exist\n            if !atom_temp.exists() {\n                let _ = std::fs::create_dir_all(&atom_temp);\n            }\n            if let Ok(canonical) = atom_temp.canonicalize() {\n                allowed_dirs.push(canonical);\n            }\n        }\n        \n        // Remove duplicates and sort\n        allowed_dirs.sort();\n        allowed_dirs.dedup();\n        \n        Self {\n            allowed_directories: allowed_dirs,\n            max_project_size: 10 * 1024 * 1024 * 1024, // 10GB\n            max_file_size: 100 * 1024 * 1024, // 100MB\n            max_file_count: 100_000,\n        }\n    }\n}"},"tool_response":{"filePath":"C:\\Users\\1\\Documents\\GitHub\\MAGRAY\\src-tauri\\src\\project_manager.rs","oldString":"impl Default for ProjectSandboxConfig {\n    fn default() -> Self {\n        let mut allowed_dirs = Vec::new();\n        \n        // Add user's home directory subdirectories\n        if let Some(home) = dirs::home_dir() {\n            allowed_dirs.push(home.join(\"Documents\"));\n            allowed_dirs.push(home.join(\"Projects\"));\n            allowed_dirs.push(home.join(\"workspace\"));\n            allowed_dirs.push(home.join(\"dev\"));\n            allowed_dirs.push(home.join(\"src\"));\n            allowed_dirs.push(home.join(\"Desktop\"));\n        }\n        \n        // Add current working directory if not in system location\n        if let Ok(cwd) = std::env::current_dir() {\n            let cwd_str = cwd.to_string_lossy().to_lowercase();\n            #[cfg(target_os = \"windows\")]\n            let is_system = cwd_str.starts_with(\"c:\\\\windows\") || cwd_str.starts_with(\"c:\\\\program\");\n            #[cfg(not(target_os = \"windows\"))]\n            let is_system = cwd_str.starts_with(\"/etc\") || cwd_str.starts_with(\"/sys\");\n            \n            if !is_system {\n                allowed_dirs.push(cwd);\n            }\n        }\n        \n        Self {\n            allowed_directories: allowed_dirs,\n            max_project_size: 10 * 1024 * 1024 * 1024, // 10GB\n            max_file_size: 100 * 1024 * 1024, // 100MB\n            max_file_count: 100_000,\n        }\n    }\n}","newString":"impl Default for ProjectSandboxConfig {\n    fn default() -> Self {\n        let mut allowed_dirs = Vec::new();\n        \n        // Add user's home directory subdirectories with validation\n        if let Some(home) = dirs::home_dir() {\n            // List of subdirectories to allow under home\n            let subdirs = [\n                \"Documents\",\n                \"Projects\", \n                \"workspace\",\n                \"dev\",\n                \"src\",\n                \"Desktop\",\n                \"GitHub\",\n                \"repos\",\n                \"code\",\n            ];\n            \n            for subdir in &subdirs {\n                let path = home.join(subdir);\n                // Only add if directory exists and can be canonicalized\n                if path.exists() && path.is_dir() {\n                    if let Ok(canonical) = path.canonicalize() {\n                        // Verify it's still under home after canonicalization (no symlink escape)\n                        if let Ok(canonical_home) = home.canonicalize() {\n                            if canonical.starts_with(&canonical_home) {\n                                allowed_dirs.push(canonical);\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        \n        // Add current working directory if safe\n        if let Ok(cwd) = std::env::current_dir() {\n            if let Ok(canonical_cwd) = cwd.canonicalize() {\n                let cwd_str = canonical_cwd.to_string_lossy().to_lowercase();\n                \n                // Block system directories across all platforms\n                let is_system = \n                    // Windows system directories\n                    cwd_str.starts_with(\"c:\\\\windows\") || \n                    cwd_str.starts_with(\"c:\\\\program files\") ||\n                    cwd_str.starts_with(\"c:\\\\programdata\") ||\n                    // Unix/Linux system directories\n                    cwd_str.starts_with(\"/etc\") || \n                    cwd_str.starts_with(\"/sys\") ||\n                    cwd_str.starts_with(\"/proc\") ||\n                    cwd_str.starts_with(\"/dev\") ||\n                    cwd_str.starts_with(\"/boot\") ||\n                    cwd_str.starts_with(\"/bin\") ||\n                    cwd_str.starts_with(\"/sbin\") ||\n                    cwd_str.starts_with(\"/lib\") ||\n                    cwd_str.starts_with(\"/usr/bin\") ||\n                    cwd_str.starts_with(\"/usr/sbin\") ||\n                    // macOS system directories\n                    cwd_str.starts_with(\"/system\") ||\n                    cwd_str.starts_with(\"/library\") ||\n                    cwd_str.starts_with(\"/private\");\n                \n                if !is_system {\n                    allowed_dirs.push(canonical_cwd);\n                }\n            }\n        }\n        \n        // Add temp directory for scratch projects (sandboxed)\n        if let Some(temp_dir) = dirs::data_local_dir() {\n            let atom_temp = temp_dir.join(\"atom-ide\").join(\"projects\");\n            // Create if doesn't exist\n            if !atom_temp.exists() {\n                let _ = std::fs::create_dir_all(&atom_temp);\n            }\n            if let Ok(canonical) = atom_temp.canonicalize() {\n                allowed_dirs.push(canonical);\n            }\n        }\n        \n        // Remove duplicates and sort\n        allowed_dirs.sort();\n        allowed_dirs.dedup();\n        \n        Self {\n            allowed_directories: allowed_dirs,\n            max_project_size: 10 * 1024 * 1024 * 1024, // 10GB\n            max_file_size: 100 * 1024 * 1024, // 100MB\n            max_file_count: 100_000,\n        }\n    }\n}","originalFile":"use anyhow::Result;\nuse dashmap::DashMap;\nuse serde::{Deserialize, Serialize};\nuse std::path::PathBuf;\nuse std::sync::{Arc, Weak};\nuse tokio::sync::{RwLock, mpsc, Mutex};\nuse tokio::time::timeout;\nuse uuid::Uuid;\nuse walkdir::WalkDir;\nuse notify::{Watcher, RecursiveMode, Event, RecommendedWatcher};\nuse notify::EventKind;\nuse tracing::{info, warn, error, debug};\nuse std::sync::atomic::{AtomicBool, Ordering};\nuse std::time::Duration;\n\n/// Unique identifier for a project\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)]\npub struct ProjectId(Uuid);\n\nimpl ProjectId {\n    pub fn new() -> Self {\n        Self(Uuid::new_v4())\n    }\n    \n    pub fn from_uuid(uuid: Uuid) -> Self {\n        Self(uuid)\n    }\n    \n    pub fn as_uuid(&self) -> Uuid {\n        self.0\n    }\n}\n\nimpl Default for ProjectId {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\n/// Project configuration with validation\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ProjectConfig {\n    pub name: String,\n    pub project_type: ProjectType,\n    pub root_path: PathBuf,\n    pub ignore_patterns: Vec<String>,\n    pub include_patterns: Vec<String>,\n    pub build_command: Option<String>,\n    pub test_command: Option<String>,\n    pub language_servers: Vec<LanguageServerConfig>,\n}\n\nimpl ProjectConfig {\n    /// Validate configuration for security and correctness\n    pub fn validate(&self) -> Result<()> {\n        if self.name.trim().is_empty() {\n            return Err(anyhow::anyhow!(\"Project name cannot be empty\"));\n        }\n        \n        if self.name.len() > 255 {\n            return Err(anyhow::anyhow!(\"Project name too long (max 255 characters)\"));\n        }\n        \n        // Validate name contains only safe characters\n        if !self.name.chars().all(|c| c.is_alphanumeric() || matches!(c, ' ' | '_' | '-' | '.')) {\n            return Err(anyhow::anyhow!(\"Project name contains invalid characters\"));\n        }\n        \n        if !self.root_path.is_absolute() {\n            return Err(anyhow::anyhow!(\"Root path must be absolute\"));\n        }\n        \n        // Validate ignore patterns for security\n        for pattern in &self.ignore_patterns {\n            if pattern.contains(\"..\") {\n                return Err(anyhow::anyhow!(\"Invalid ignore pattern with directory traversal: {}\", pattern));\n            }\n        }\n        \n        // Validate commands don't contain dangerous patterns\n        if let Some(ref cmd) = self.build_command {\n            if cmd.contains(\"rm -rf\") || cmd.contains(\"del /f\") || cmd.contains(\"format\") {\n                return Err(anyhow::anyhow!(\"Potentially dangerous build command detected\"));\n            }\n        }\n        \n        if let Some(ref cmd) = self.test_command {\n            if cmd.contains(\"rm -rf\") || cmd.contains(\"del /f\") || cmd.contains(\"format\") {\n                return Err(anyhow::anyhow!(\"Potentially dangerous test command detected\"));\n            }\n        }\n        \n        Ok(())\n    }\n}\n\nimpl Default for ProjectConfig {\n    fn default() -> Self {\n        Self {\n            name: \"Untitled Project\".to_string(),\n            project_type: ProjectType::Generic,\n            root_path: PathBuf::new(),\n            ignore_patterns: vec![\n                \".git\".to_string(),\n                \"node_modules\".to_string(),\n                \"target\".to_string(),\n                \".DS_Store\".to_string(),\n                \"*.tmp\".to_string(),\n            ],\n            include_patterns: vec![\"*\".to_string()],\n            build_command: None,\n            test_command: None,\n            language_servers: Vec::new(),\n        }\n    }\n}\n\n/// Supported project types\n#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]\npub enum ProjectType {\n    Rust,\n    JavaScript,\n    TypeScript,\n    Python,\n    Go,\n    Java,\n    CSharp,\n    CPlusPlus,\n    Web,\n    Generic,\n}\n\n/// Language server configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct LanguageServerConfig {\n    pub name: String,\n    pub command: String,\n    pub args: Vec<String>,\n    pub file_extensions: Vec<String>,\n}\n\n/// File tree structure\n#[derive(Debug, Clone)]\npub struct FileTree {\n    pub root: PathBuf,\n    pub files: Vec<FileEntry>,\n    pub directories: Vec<DirectoryEntry>,\n    pub total_files: usize,\n    pub total_size: u64,\n}\n\n#[derive(Debug, Clone)]\npub struct FileEntry {\n    pub path: PathBuf,\n    pub relative_path: PathBuf,\n    pub size: u64,\n    pub extension: Option<String>,\n    pub is_text: bool,\n}\n\n#[derive(Debug, Clone)]\npub struct DirectoryEntry {\n    pub path: PathBuf,\n    pub relative_path: PathBuf,\n    pub file_count: usize,\n}\n\n/// Symbol index for fast navigation\n#[derive(Debug, Default)]\npub struct SymbolIndex {\n    pub symbols: DashMap<String, Vec<Symbol>>,\n    pub file_symbols: DashMap<PathBuf, Vec<Symbol>>,\n}\n\n#[derive(Debug, Clone)]\npub struct Symbol {\n    pub name: String,\n    pub kind: SymbolKind,\n    pub location: SymbolLocation,\n    pub container: Option<String>,\n}\n\n#[derive(Debug, Clone)]\npub enum SymbolKind {\n    Function,\n    Class,\n    Interface,\n    Variable,\n    Constant,\n    Module,\n    Namespace,\n    Property,\n    Method,\n    Struct,\n    Enum,\n    Trait,\n}\n\n#[derive(Debug, Clone)]\npub struct SymbolLocation {\n    pub file: PathBuf,\n    pub line: u32,\n    pub column: u32,\n    pub range: Option<(u32, u32)>, // (start_line, end_line)\n}\n\n/// Dependency graph analysis\n#[derive(Debug, Default)]\npub struct DependencyGraph {\n    dependencies: Vec<Dependency>,\n    dev_dependencies: Vec<Dependency>,\n    build_dependencies: Vec<Dependency>,\n}\n\n#[derive(Debug, Clone)]\npub struct Dependency {\n    pub name: String,\n    pub version: String,\n    pub source: DependencySource,\n}\n\n#[derive(Debug, Clone)]\npub enum DependencySource {\n    Registry,\n    Git { url: String, branch: Option<String> },\n    Path { path: PathBuf },\n}\n\n/// File system events\n#[derive(Debug, Clone)]\npub enum FileSystemEvent {\n    Created(PathBuf),\n    Modified(PathBuf),\n    Deleted(PathBuf),\n    Renamed(PathBuf, PathBuf),\n}\n\n/// File watcher handle with proper lifecycle management\npub struct FileWatcherHandle {\n    _watcher: RecommendedWatcher,\n    shutdown_signal: Arc<AtomicBool>,\n    task_handle: tokio::task::JoinHandle<()>,\n}\n\nimpl FileWatcherHandle {\n    pub async fn shutdown(self) -> Result<()> {\n        self.shutdown_signal.store(true, Ordering::Relaxed);\n        self.task_handle.await?;\n        Ok(())\n    }\n}\n\n/// Project structure\npub struct Project {\n    pub id: ProjectId,\n    pub root_path: PathBuf,\n    pub config: ProjectConfig,\n    pub file_tree: Arc<RwLock<FileTree>>,\n    pub symbol_index: Arc<SymbolIndex>,\n    pub dependencies: Arc<RwLock<DependencyGraph>>,\n    pub last_indexed: Option<std::time::SystemTime>,\n    pub file_watcher: Option<FileWatcherHandle>,\n}\n\nimpl Project {\n    pub async fn shutdown(&mut self) -> Result<()> {\n        if let Some(watcher) = self.file_watcher.take() {\n            watcher.shutdown().await?;\n        }\n        Ok(())\n    }\n}\n\n/// Event processor with proper backpressure and error handling\npub struct EventProcessor {\n    receiver: Arc<Mutex<Option<mpsc::Receiver<FileSystemEvent>>>>,\n    shutdown_signal: Arc<AtomicBool>,\n    max_events_per_second: usize,\n    dropped_events_counter: Arc<std::sync::atomic::AtomicU64>,\n}\n\nimpl EventProcessor {\n    pub fn new(capacity: usize, max_events_per_second: usize) -> (Self, mpsc::Sender<FileSystemEvent>) {\n        let (sender, receiver) = mpsc::channel(capacity);\n        \n        (\n            Self {\n                receiver: Arc::new(Mutex::new(Some(receiver))),\n                shutdown_signal: Arc::new(AtomicBool::new(false)),\n                max_events_per_second,\n                dropped_events_counter: Arc::new(std::sync::atomic::AtomicU64::new(0)),\n            },\n            sender,\n        )\n    }\n    \n    pub async fn start_processing<F>(&self, mut handler: F) -> Result<()>\n    where\n        F: FnMut(FileSystemEvent) -> Result<()> + Send + 'static,\n    {\n        let mut receiver = self.receiver.lock().await.take()\n            .ok_or_else(|| anyhow::anyhow!(\"Event processor already started\"))?;\n        \n        let shutdown_signal = self.shutdown_signal.clone();\n        let max_events = self.max_events_per_second;\n        let dropped_counter = self.dropped_events_counter.clone();\n        \n        tokio::spawn(async move {\n            let mut last_second = std::time::Instant::now();\n            let mut events_this_second = 0;\n            \n            while !shutdown_signal.load(Ordering::Relaxed) {\n                let now = std::time::Instant::now();\n                if now.duration_since(last_second) >= std::time::Duration::from_secs(1) {\n                    if events_this_second >= max_events {\n                        debug!(\"Rate limited {} events in the last second\", events_this_second - max_events);\n                    }\n                    last_second = now;\n                    events_this_second = 0;\n                }\n                \n                match tokio::time::timeout(\n                    std::time::Duration::from_millis(100),\n                    receiver.recv()\n                ).await {\n                    Ok(Some(event)) => {\n                        if events_this_second >= max_events {\n                            dropped_counter.fetch_add(1, Ordering::Relaxed);\n                            continue;\n                        }\n                        \n                        events_this_second += 1;\n                        \n                        if let Err(e) = handler(event) {\n                            error!(\"Error processing file system event: {}\", e);\n                        }\n                    }\n                    Ok(None) => {\n                        debug!(\"Event channel closed\");\n                        break;\n                    }\n                    Err(_) => {\n                        continue;\n                    }\n                }\n            }\n            \n            info!(\"Event processor shutdown completed\");\n        });\n        \n        Ok(())\n    }\n    \n    pub fn shutdown(&self) {\n        self.shutdown_signal.store(true, Ordering::Relaxed);\n    }\n    \n    pub fn get_dropped_events_count(&self) -> u64 {\n        self.dropped_events_counter.load(Ordering::Relaxed)\n    }\n}\n\n/// Configuration for project sandbox\n#[derive(Debug, Clone)]\npub struct ProjectSandboxConfig {\n    /// Allowed base directories for projects\n    pub allowed_directories: Vec<PathBuf>,\n    /// Maximum project size in bytes\n    pub max_project_size: u64,\n    /// Maximum file size in bytes\n    pub max_file_size: u64,\n    /// Maximum number of files in project\n    pub max_file_count: usize,\n}\n\nimpl Default for ProjectSandboxConfig {\n    fn default() -> Self {\n        let mut allowed_dirs = Vec::new();\n        \n        // Add user's home directory subdirectories\n        if let Some(home) = dirs::home_dir() {\n            allowed_dirs.push(home.join(\"Documents\"));\n            allowed_dirs.push(home.join(\"Projects\"));\n            allowed_dirs.push(home.join(\"workspace\"));\n            allowed_dirs.push(home.join(\"dev\"));\n            allowed_dirs.push(home.join(\"src\"));\n            allowed_dirs.push(home.join(\"Desktop\"));\n        }\n        \n        // Add current working directory if not in system location\n        if let Ok(cwd) = std::env::current_dir() {\n            let cwd_str = cwd.to_string_lossy().to_lowercase();\n            #[cfg(target_os = \"windows\")]\n            let is_system = cwd_str.starts_with(\"c:\\\\windows\") || cwd_str.starts_with(\"c:\\\\program\");\n            #[cfg(not(target_os = \"windows\"))]\n            let is_system = cwd_str.starts_with(\"/etc\") || cwd_str.starts_with(\"/sys\");\n            \n            if !is_system {\n                allowed_dirs.push(cwd);\n            }\n        }\n        \n        Self {\n            allowed_directories: allowed_dirs,\n            max_project_size: 10 * 1024 * 1024 * 1024, // 10GB\n            max_file_size: 100 * 1024 * 1024, // 100MB\n            max_file_count: 100_000,\n        }\n    }\n}\n\n/// Main project manager with proper resource management\npub struct ProjectManager {\n    active_projects: Arc<DashMap<ProjectId, Project>>,\n    event_processor: Arc<EventProcessor>,\n    event_sender: mpsc::Sender<FileSystemEvent>,\n    shutdown_signal: Arc<AtomicBool>,\n    sandbox_config: ProjectSandboxConfig,\n}\n\nimpl Default for ProjectManager {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\nimpl ProjectManager {\n    pub fn new() -> Self {\n        let (event_processor, event_sender) = EventProcessor::new(1000, 100);\n        \n        Self {\n            active_projects: Arc::new(DashMap::new()),\n            event_processor: Arc::new(event_processor),\n            event_sender,\n            shutdown_signal: Arc::new(AtomicBool::new(false)),\n        }\n    }\n    \n    pub async fn start(&self) -> Result<()> {\n        let event_processor = self.event_processor.clone();\n        let projects = Arc::clone(&self.active_projects);\n        \n        event_processor.start_processing(move |event| {\n            debug!(\"Processing file system event: {:?}\", event);\n            \n            match event {\n                FileSystemEvent::Modified(path) => {\n                    for project_entry in projects.iter() {\n                        let project = project_entry.value();\n                        if path.starts_with(&project.root_path) {\n                            debug!(\"File modified in project {}: {:?}\", project.config.name, path);\n                        }\n                    }\n                }\n                FileSystemEvent::Created(path) => {\n                    debug!(\"File created: {:?}\", path);\n                }\n                FileSystemEvent::Deleted(path) => {\n                    debug!(\"File deleted: {:?}\", path);\n                }\n                FileSystemEvent::Renamed(old_path, new_path) => {\n                    debug!(\"File renamed: {:?} -> {:?}\", old_path, new_path);\n                }\n            }\n            \n            Ok(())\n        }).await?;\n        \n        Ok(())\n    }\n    \n    /// Open a project from a given path with full validation\n    pub async fn open_project(&self, path: PathBuf) -> Result<ProjectId> {\n        info!(\"Opening project at: {:?}\", path);\n        \n        // Validate and sanitize path\n        let canonical_path = self.validate_and_canonicalize_path(&path)?;\n        \n        if !canonical_path.exists() {\n            return Err(anyhow::anyhow!(\"Project path does not exist: {:?}\", canonical_path));\n        }\n        \n        if !canonical_path.is_dir() {\n            return Err(anyhow::anyhow!(\"Project path is not a directory: {:?}\", canonical_path));\n        }\n        \n        let project_type = self.detect_project_type(&path).await?;\n        let mut config = self.load_or_create_config(&path, project_type).await?;\n        config.root_path = path.clone();\n        \n        config.validate()?;\n        \n        let project_id = ProjectId::new();\n        \n        let file_tree = self.scan_file_tree(&path, &config).await?;\n        let dependencies = self.analyze_dependencies(&path, &config.project_type).await?;\n        let file_watcher = self.setup_file_watching(&path).await?;\n        \n        let project = Project {\n            id: project_id,\n            root_path: path.clone(),\n            config,\n            file_tree: Arc::new(RwLock::new(file_tree)),\n            symbol_index: Arc::new(SymbolIndex::default()),\n            dependencies: Arc::new(RwLock::new(dependencies)),\n            last_indexed: Some(std::time::SystemTime::now()),\n            file_watcher: Some(file_watcher),\n        };\n        \n        self.start_background_indexing(project_id, &project).await?;\n        \n        self.active_projects.insert(project_id, project);\n        \n        info!(\"Successfully opened project: {:?} with ID: {:?}\", path, project_id);\n        \n        Ok(project_id)\n    }\n    \n    /// Close a project with proper cleanup\n    pub async fn close_project(&self, project_id: ProjectId) -> Result<bool> {\n        if let Some((_, mut project)) = self.active_projects.remove(&project_id) {\n            info!(\"Closing project: {:?}\", project.root_path);\n            project.shutdown().await?;\n            Ok(true)\n        } else {\n            Ok(false)\n        }\n    }\n    \n    /// Shutdown the project manager and all resources\n    pub async fn shutdown(&self) -> Result<()> {\n        info!(\"Shutting down ProjectManager\");\n        \n        self.shutdown_signal.store(true, Ordering::Relaxed);\n        self.event_processor.shutdown();\n        \n        let project_ids: Vec<ProjectId> = self.active_projects.iter()\n            .map(|entry| *entry.key())\n            .collect();\n        \n        for project_id in project_ids {\n            self.close_project(project_id).await?;\n        }\n        \n        info!(\"ProjectManager shutdown completed\");\n        Ok(())\n    }\n    \n    pub fn get_project(&self, project_id: ProjectId) -> Option<dashmap::mapref::one::Ref<'_, ProjectId, Project>> {\n        self.active_projects.get(&project_id)\n    }\n    \n    pub fn list_projects(&self) -> Vec<ProjectId> {\n        self.active_projects.iter().map(|entry| *entry.key()).collect()\n    }\n    \n    async fn detect_project_type(&self, path: &PathBuf) -> Result<ProjectType> {\n        debug!(\"Detecting project type for: {:?}\", path);\n        \n        if path.join(\"Cargo.toml\").exists() {\n            return Ok(ProjectType::Rust);\n        }\n        \n        if path.join(\"package.json\").exists() {\n            let package_json = path.join(\"package.json\");\n            if let Ok(content) = tokio::fs::read_to_string(&package_json).await {\n                if content.contains(\"\\\"typescript\\\"\") || path.join(\"tsconfig.json\").exists() {\n                    return Ok(ProjectType::TypeScript);\n                } else {\n                    return Ok(ProjectType::JavaScript);\n                }\n            }\n        }\n        \n        if path.join(\"requirements.txt\").exists() \n            || path.join(\"setup.py\").exists() \n            || path.join(\"pyproject.toml\").exists() {\n            return Ok(ProjectType::Python);\n        }\n        \n        if path.join(\"go.mod\").exists() {\n            return Ok(ProjectType::Go);\n        }\n        \n        if path.join(\"pom.xml\").exists() || path.join(\"build.gradle\").exists() {\n            return Ok(ProjectType::Java);\n        }\n        \n        if path.join(\"CMakeLists.txt\").exists() || path.join(\"Makefile\").exists() {\n            return Ok(ProjectType::CPlusPlus);\n        }\n        \n        if path.join(\"index.html\").exists() \n            || path.join(\"src\").join(\"index.html\").exists()\n            || path.join(\"public\").join(\"index.html\").exists() {\n            return Ok(ProjectType::Web);\n        }\n        \n        Ok(ProjectType::Generic)\n    }\n    \n    async fn load_or_create_config(&self, path: &PathBuf, project_type: ProjectType) -> Result<ProjectConfig> {\n        let config_path = path.join(\".atom-ide.toml\");\n        \n        if config_path.exists() {\n            match tokio::fs::read_to_string(&config_path).await {\n                Ok(content) => {\n                    if content.len() > 1024 * 1024 {\n                        return Err(anyhow::anyhow!(\"Configuration file too large (max 1MB)\"));\n                    }\n                    \n                    match toml::from_str::<ProjectConfig>(&content) {\n                        Ok(config) => {\n                            config.validate()?;\n                            debug!(\"Loaded existing project config\");\n                            return Ok(config);\n                        }\n                        Err(e) => {\n                            warn!(\"Failed to parse project config, using defaults: {}\", e);\n                        }\n                    }\n                }\n                Err(e) => {\n                    warn!(\"Failed to read project config file: {}\", e);\n                }\n            }\n        }\n        \n        let project_name = path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .unwrap_or(\"Untitled Project\")\n            .to_string();\n        \n        let mut config = ProjectConfig::default();\n        config.name = project_name;\n        config.project_type = project_type;\n        config.root_path = path.clone();\n        \n        match config.project_type {\n            ProjectType::Rust => {\n                config.build_command = Some(\"cargo build\".to_string());\n                config.test_command = Some(\"cargo test\".to_string());\n                config.ignore_patterns.push(\"target/**\".to_string());\n            }\n            ProjectType::JavaScript | ProjectType::TypeScript => {\n                config.build_command = Some(\"npm run build\".to_string());\n                config.test_command = Some(\"npm test\".to_string());\n                config.ignore_patterns.push(\"node_modules/**\".to_string());\n                config.ignore_patterns.push(\"dist/**\".to_string());\n            }\n            ProjectType::Python => {\n                config.ignore_patterns.push(\"__pycache__/**\".to_string());\n                config.ignore_patterns.push(\"*.pyc\".to_string());\n                config.ignore_patterns.push(\".venv/**\".to_string());\n                config.ignore_patterns.push(\"venv/**\".to_string());\n            }\n            _ => {}\n        }\n        \n        Ok(config)\n    }\n    \n    async fn scan_file_tree(&self, path: &PathBuf, config: &ProjectConfig) -> Result<FileTree> {\n        debug!(\"Scanning file tree for: {:?}\", path);\n        \n        let path_clone = path.clone();\n        let ignore_patterns = config.ignore_patterns.clone();\n        \n        let (files, directories, total_files, total_size) = tokio::task::spawn_blocking(move || {\n            let mut files = Vec::new();\n            let mut directories = Vec::new();\n            let mut total_files = 0;\n            let mut total_size = 0;\n            \n            for entry in WalkDir::new(&path_clone)\n                .follow_links(false)\n                .max_depth(10) // Prevent deep recursion\n                .into_iter()\n                .filter_entry(|e| {\n                    let path_str = e.path().to_string_lossy();\n                    !ignore_patterns.iter().any(|pattern| {\n                        Self::pattern_matches(&path_str, pattern)\n                    })\n                }) {\n                \n                if let Ok(entry) = entry {\n                    let entry_path = entry.path().to_path_buf();\n                    \n                    if let Ok(relative_path) = entry_path.strip_prefix(&path_clone) {\n                        let relative_path = relative_path.to_path_buf();\n                        \n                        if entry_path.is_file() {\n                            if let Ok(metadata) = entry.metadata() {\n                                let size = metadata.len();\n                                let extension = entry_path\n                                    .extension()\n                                    .and_then(|ext| ext.to_str())\n                                    .map(|ext| ext.to_lowercase());\n                                \n                                let is_text = Self::is_text_file(&extension);\n                                \n                                files.push(FileEntry {\n                                    path: entry_path,\n                                    relative_path,\n                                    size,\n                                    extension,\n                                    is_text,\n                                });\n                                \n                                total_files += 1;\n                                total_size += size;\n                            }\n                        } else if entry_path.is_dir() && entry_path != path_clone {\n                            directories.push(DirectoryEntry {\n                                path: entry_path,\n                                relative_path,\n                                file_count: 0,\n                            });\n                        }\n                    }\n                }\n            }\n            \n            (files, directories, total_files, total_size)\n        }).await?;\n        \n        info!(\"Scanned {} files and {} directories (total size: {} bytes)\", \n              total_files, directories.len(), total_size);\n        \n        Ok(FileTree {\n            root: path.clone(),\n            files,\n            directories,\n            total_files,\n            total_size,\n        })\n    }\n    \n    fn pattern_matches(path: &str, pattern: &str) -> bool {\n        if pattern.ends_with(\"/**\") {\n            let prefix = &pattern[..pattern.len() - 3];\n            path.contains(prefix)\n        } else if pattern.starts_with(\"*.\") {\n            let suffix = &pattern[1..];\n            path.ends_with(suffix)\n        } else {\n            path.contains(pattern)\n        }\n    }\n    \n    fn is_text_file(extension: &Option<String>) -> bool {\n        match extension {\n            Some(ext) => matches!(ext.as_str(),\n                \"rs\" | \"js\" | \"ts\" | \"py\" | \"go\" | \"java\" | \"cpp\" | \"c\" | \"h\" | \n                \"cs\" | \"php\" | \"rb\" | \"swift\" | \"kt\" | \"scala\" | \"clj\" | \"elm\" |\n                \"html\" | \"css\" | \"scss\" | \"sass\" | \"less\" | \"xml\" | \"json\" | \n                \"yaml\" | \"yml\" | \"toml\" | \"ini\" | \"cfg\" | \"conf\" | \"md\" | \"txt\" |\n                \"sh\" | \"bash\" | \"zsh\" | \"fish\" | \"ps1\" | \"bat\" | \"cmd\"\n            ),\n            None => false,\n        }\n    }\n    \n    async fn analyze_dependencies(&self, path: &PathBuf, project_type: &ProjectType) -> Result<DependencyGraph> {\n        debug!(\"Analyzing dependencies for: {:?}\", path);\n        \n        match project_type {\n            ProjectType::Rust => self.analyze_rust_dependencies(path).await,\n            ProjectType::JavaScript | ProjectType::TypeScript => self.analyze_npm_dependencies(path).await,\n            ProjectType::Python => self.analyze_python_dependencies(path).await,\n            _ => Ok(DependencyGraph::default()),\n        }\n    }\n    \n    async fn analyze_rust_dependencies(&self, path: &PathBuf) -> Result<DependencyGraph> {\n        let cargo_toml = path.join(\"Cargo.toml\");\n        \n        if !cargo_toml.exists() {\n            return Ok(DependencyGraph::default());\n        }\n        \n        let content = tokio::fs::read_to_string(&cargo_toml).await?;\n        \n        let parsed: toml::Value = toml::from_str(&content)\n            .map_err(|e| anyhow::anyhow!(\"Failed to parse Cargo.toml: {}\", e))?;\n        \n        let mut dependencies = Vec::new();\n        let mut dev_dependencies = Vec::new();\n        let mut build_dependencies = Vec::new();\n        \n        if let Some(deps) = parsed.get(\"dependencies\").and_then(|d| d.as_table()) {\n            for (name, value) in deps {\n                let dep = self.parse_cargo_dependency(name, value)?;\n                dependencies.push(dep);\n            }\n        }\n        \n        if let Some(deps) = parsed.get(\"dev-dependencies\").and_then(|d| d.as_table()) {\n            for (name, value) in deps {\n                let dep = self.parse_cargo_dependency(name, value)?;\n                dev_dependencies.push(dep);\n            }\n        }\n        \n        if let Some(deps) = parsed.get(\"build-dependencies\").and_then(|d| d.as_table()) {\n            for (name, value) in deps {\n                let dep = self.parse_cargo_dependency(name, value)?;\n                build_dependencies.push(dep);\n            }\n        }\n        \n        Ok(DependencyGraph {\n            dependencies,\n            dev_dependencies,\n            build_dependencies,\n        })\n    }\n    \n    fn parse_cargo_dependency(&self, name: &str, value: &toml::Value) -> Result<Dependency> {\n        match value {\n            toml::Value::String(version) => {\n                Ok(Dependency {\n                    name: name.to_string(),\n                    version: version.clone(),\n                    source: DependencySource::Registry,\n                })\n            }\n            toml::Value::Table(table) => {\n                let version = table.get(\"version\")\n                    .and_then(|v| v.as_str())\n                    .unwrap_or(\"*\")\n                    .to_string();\n                \n                let source = if let Some(git) = table.get(\"git\").and_then(|g| g.as_str()) {\n                    let branch = table.get(\"branch\").and_then(|b| b.as_str()).map(|s| s.to_string());\n                    DependencySource::Git { \n                        url: git.to_string(), \n                        branch \n                    }\n                } else if let Some(path_val) = table.get(\"path\").and_then(|p| p.as_str()) {\n                    DependencySource::Path { \n                        path: PathBuf::from(path_val) \n                    }\n                } else {\n                    DependencySource::Registry\n                };\n                \n                Ok(Dependency {\n                    name: name.to_string(),\n                    version,\n                    source,\n                })\n            }\n            _ => Err(anyhow::anyhow!(\"Invalid dependency format for {}\", name))\n        }\n    }\n    \n    async fn analyze_npm_dependencies(&self, path: &PathBuf) -> Result<DependencyGraph> {\n        let package_json = path.join(\"package.json\");\n        \n        if !package_json.exists() {\n            return Ok(DependencyGraph::default());\n        }\n        \n        let content = tokio::fs::read_to_string(&package_json).await?;\n        let parsed: serde_json::Value = serde_json::from_str(&content)\n            .map_err(|e| anyhow::anyhow!(\"Failed to parse package.json: {}\", e))?;\n        \n        let mut dependencies = Vec::new();\n        let mut dev_dependencies = Vec::new();\n        \n        if let Some(deps) = parsed.get(\"dependencies\").and_then(|d| d.as_object()) {\n            for (name, version) in deps {\n                if let Some(version_str) = version.as_str() {\n                    dependencies.push(Dependency {\n                        name: name.clone(),\n                        version: version_str.to_string(),\n                        source: DependencySource::Registry,\n                    });\n                }\n            }\n        }\n        \n        if let Some(deps) = parsed.get(\"devDependencies\").and_then(|d| d.as_object()) {\n            for (name, version) in deps {\n                if let Some(version_str) = version.as_str() {\n                    dev_dependencies.push(Dependency {\n                        name: name.clone(),\n                        version: version_str.to_string(),\n                        source: DependencySource::Registry,\n                    });\n                }\n            }\n        }\n        \n        Ok(DependencyGraph {\n            dependencies,\n            dev_dependencies,\n            build_dependencies: Vec::new(),\n        })\n    }\n    \n    async fn analyze_python_dependencies(&self, path: &PathBuf) -> Result<DependencyGraph> {\n        let mut dependencies = Vec::new();\n        \n        // Check requirements.txt\n        let requirements_txt = path.join(\"requirements.txt\");\n        if requirements_txt.exists() {\n            let content = tokio::fs::read_to_string(&requirements_txt).await?;\n            \n            for line in content.lines() {\n                let line = line.trim();\n                if !line.is_empty() && !line.starts_with('#') && !line.starts_with('-') {\n                    let dep = self.parse_python_requirement(line)?;\n                    dependencies.push(dep);\n                }\n            }\n        }\n        \n        // Check pyproject.toml\n        let pyproject_toml = path.join(\"pyproject.toml\");\n        if pyproject_toml.exists() {\n            let content = tokio::fs::read_to_string(&pyproject_toml).await?;\n            let parsed: toml::Value = toml::from_str(&content)\n                .map_err(|e| anyhow::anyhow!(\"Failed to parse pyproject.toml: {}\", e))?;\n            \n            if let Some(deps) = parsed\n                .get(\"project\")\n                .and_then(|p| p.get(\"dependencies\"))\n                .and_then(|d| d.as_array()) {\n                \n                for dep_val in deps {\n                    if let Some(dep_str) = dep_val.as_str() {\n                        let dep = self.parse_python_requirement(dep_str)?;\n                        dependencies.push(dep);\n                    }\n                }\n            }\n        }\n        \n        Ok(DependencyGraph {\n            dependencies,\n            dev_dependencies: Vec::new(),\n            build_dependencies: Vec::new(),\n        })\n    }\n    \n    fn parse_python_requirement(&self, requirement: &str) -> Result<Dependency> {\n        // Parse formats like \"package==1.0.0\", \"package>=1.0.0\", \"package\", etc.\n        let parts: Vec<&str> = requirement.split(&['=', '>', '<', '!', '~'][..]).collect();\n        let name = parts[0].trim().to_string();\n        \n        if name.is_empty() {\n            return Err(anyhow::anyhow!(\"Invalid requirement format: {}\", requirement));\n        }\n        \n        let version = if parts.len() > 1 {\n            parts[1..].join(\"\").trim().to_string()\n        } else {\n            \"*\".to_string()\n        };\n        \n        Ok(Dependency {\n            name,\n            version,\n            source: DependencySource::Registry,\n        })\n    }\n    \n    async fn setup_file_watching(&self, path: &PathBuf) -> Result<FileWatcherHandle> {\n        debug!(\"Setting up file watching for: {:?}\", path);\n        \n        let sender = self.event_sender.clone();\n        let path_clone = path.clone();\n        let shutdown_signal = Arc::new(AtomicBool::new(false));\n        let shutdown_signal_clone = shutdown_signal.clone();\n        \n        let mut watcher = notify::recommended_watcher(move |res: notify::Result<Event>| {\n            match res {\n                Ok(event) => {\n                    let fs_event = match event.kind {\n                        EventKind::Create(_) => {\n                            if let Some(path) = event.paths.first() {\n                                Some(FileSystemEvent::Created(path.clone()))\n                            } else {\n                                None\n                            }\n                        }\n                        EventKind::Modify(_) => {\n                            if let Some(path) = event.paths.first() {\n                                Some(FileSystemEvent::Modified(path.clone()))\n                            } else {\n                                None\n                            }\n                        }\n                        EventKind::Remove(_) => {\n                            if let Some(path) = event.paths.first() {\n                                Some(FileSystemEvent::Deleted(path.clone()))\n                            } else {\n                                None\n                            }\n                        }\n                        _ => None,\n                    };\n                    \n                    if let Some(fs_event) = fs_event {\n                        match sender.try_send(fs_event) {\n                            Ok(()) => {},\n                            Err(mpsc::error::TrySendError::Full(_)) => {\n                                // Channel is full - this is handled by rate limiting in EventProcessor\n                            },\n                            Err(mpsc::error::TrySendError::Closed(_)) => {\n                                debug!(\"File watcher event channel closed\");\n                            }\n                        }\n                    }\n                }\n                Err(e) => error!(\"File watcher error: {}\", e),\n            }\n        })?;\n        \n        watcher.watch(&path_clone, RecursiveMode::Recursive)?;\n        \n        let task_handle = tokio::spawn(async move {\n            while !shutdown_signal_clone.load(Ordering::Relaxed) {\n                tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;\n            }\n            debug!(\"File watcher task for {:?} shutdown\", path_clone);\n        });\n        \n        info!(\"Started file watching for: {:?}\", path);\n        \n        Ok(FileWatcherHandle {\n            _watcher: watcher,\n            shutdown_signal,\n            task_handle,\n        })\n    }\n    \n    async fn start_background_indexing(&self, project_id: ProjectId, _project: &Project) -> Result<()> {\n        debug!(\"Starting background indexing for project: {:?}\", project_id);\n        \n        let shutdown_signal = self.shutdown_signal.clone();\n        \n        tokio::spawn(async move {\n            let mut indexing_interval = tokio::time::interval(tokio::time::Duration::from_secs(30));\n            \n            loop {\n                tokio::select! {\n                    _ = indexing_interval.tick() => {\n                        if shutdown_signal.load(Ordering::Relaxed) {\n                            break;\n                        }\n                        \n                        debug!(\"Performing incremental indexing for project: {:?}\", project_id);\n                        tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;\n                    }\n                    _ = tokio::time::sleep(tokio::time::Duration::from_millis(100)) => {\n                        if shutdown_signal.load(Ordering::Relaxed) {\n                            break;\n                        }\n                    }\n                }\n            }\n            \n            info!(\"Background indexing for project {:?} shutdown\", project_id);\n        });\n        \n        Ok(())\n    }\n    \n    pub async fn search_files(&self, project_id: ProjectId, pattern: &str) -> Result<Vec<FileEntry>> {\n        if let Some(project) = self.get_project(project_id) {\n            let file_tree = project.file_tree.read().await;\n            let pattern_lower = pattern.to_lowercase();\n            \n            let matching_files: Vec<FileEntry> = file_tree\n                .files\n                .iter()\n                .filter(|file| {\n                    file.relative_path\n                        .to_string_lossy()\n                        .to_lowercase()\n                        .contains(&pattern_lower)\n                })\n                .cloned()\n                .collect();\n            \n            Ok(matching_files)\n        } else {\n            Err(anyhow::anyhow!(\"Project not found: {:?}\", project_id))\n        }\n    }\n    \n    pub async fn get_project_stats(&self, project_id: ProjectId) -> Result<ProjectStats> {\n        if let Some(project) = self.get_project(project_id) {\n            let file_tree = project.file_tree.read().await;\n            let dependencies = project.dependencies.read().await;\n            \n            let stats = ProjectStats {\n                total_files: file_tree.total_files,\n                total_size: file_tree.total_size,\n                total_dependencies: dependencies.dependencies.len() + \n                                   dependencies.dev_dependencies.len() + \n                                   dependencies.build_dependencies.len(),\n                last_indexed: project.last_indexed,\n            };\n            \n            Ok(stats)\n        } else {\n            Err(anyhow::anyhow!(\"Project not found: {:?}\", project_id))\n        }\n    }\n    \n    pub fn get_dropped_events_count(&self) -> u64 {\n        self.event_processor.get_dropped_events_count()\n    }\n}\n\nimpl Drop for ProjectManager {\n    fn drop(&mut self) {\n        self.shutdown_signal.store(true, Ordering::Relaxed);\n        self.event_processor.shutdown();\n    }\n}\n\n/// Project statistics\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ProjectStats {\n    pub total_files: usize,\n    pub total_size: u64,\n    pub total_dependencies: usize,\n    pub last_indexed: Option<std::time::SystemTime>,\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use tempfile::TempDir;\n    use tokio::fs;\n    \n    #[tokio::test]\n    async fn test_project_manager_creation() {\n        let manager = ProjectManager::new();\n        assert_eq!(manager.list_projects().len(), 0);\n    }\n    \n    #[tokio::test]\n    async fn test_detect_rust_project() -> Result<()> {\n        let temp_dir = TempDir::new()?;\n        let project_path = temp_dir.path().to_path_buf();\n        \n        fs::write(project_path.join(\"Cargo.toml\"), \"[package]\\nname = \\\"test\\\"\\nversion = \\\"0.1.0\\\"\").await?;\n        \n        let manager = ProjectManager::new();\n        let project_type = manager.detect_project_type(&project_path).await?;\n        \n        assert_eq!(project_type, ProjectType::Rust);\n        \n        Ok(())\n    }\n    \n    #[tokio::test]\n    async fn test_project_lifecycle() -> Result<()> {\n        let temp_dir = TempDir::new()?;\n        let project_path = temp_dir.path().canonicalize()?;\n        \n        fs::write(project_path.join(\"Cargo.toml\"), \"[package]\\nname = \\\"test\\\"\\nversion = \\\"0.1.0\\\"\\n\\n[dependencies]\\nserde = \\\"1.0\\\"\").await?;\n        fs::create_dir(project_path.join(\"src\")).await?;\n        fs::write(project_path.join(\"src\").join(\"main.rs\"), \"fn main() { println!(\\\"Hello, world!\\\"); }\").await?;\n        \n        let manager = ProjectManager::new();\n        manager.start().await?;\n        \n        let project_id = manager.open_project(project_path).await?;\n        assert_eq!(manager.list_projects().len(), 1);\n        \n        let stats = manager.get_project_stats(project_id).await?;\n        assert!(stats.total_files >= 2);\n        assert!(stats.total_dependencies >= 1);\n        \n        let closed = manager.close_project(project_id).await?;\n        assert!(closed);\n        assert_eq!(manager.list_projects().len(), 0);\n        \n        manager.shutdown().await?;\n        \n        Ok(())\n    }\n    \n    #[tokio::test]\n    async fn test_search_files() -> Result<()> {\n        let temp_dir = TempDir::new()?;\n        let project_path = temp_dir.path().canonicalize()?;\n        \n        fs::write(project_path.join(\"main.rs\"), \"fn main() {}\").await?;\n        fs::write(project_path.join(\"lib.rs\"), \"pub fn lib() {}\").await?;\n        fs::write(project_path.join(\"config.toml\"), \"[config]\").await?;\n        \n        let manager = ProjectManager::new();\n        manager.start().await?;\n        \n        let project_id = manager.open_project(project_path).await?;\n        \n        let rust_files = manager.search_files(project_id, \"rs\").await?;\n        assert_eq!(rust_files.len(), 2);\n        \n        let main_files = manager.search_files(project_id, \"main\").await?;\n        assert_eq!(main_files.len(), 1);\n        \n        manager.shutdown().await?;\n        \n        Ok(())\n    }\n    \n    #[tokio::test]\n    async fn test_dependency_parsing() -> Result<()> {\n        let temp_dir = TempDir::new()?;\n        let project_path = temp_dir.path().canonicalize()?;\n        \n        let cargo_toml = r#\"\n[package]\nname = \"test\"\nversion = \"0.1.0\"\n\n[dependencies]\nserde = \"1.0\"\ntokio = { version = \"1.0\", features = [\"full\"] }\nlocal-dep = { path = \"../local\" }\n\n[dev-dependencies]\ncriterion = \"0.5\"\n\"#;\n        \n        fs::write(project_path.join(\"Cargo.toml\"), cargo_toml).await?;\n        \n        let manager = ProjectManager::new();\n        let deps = manager.analyze_rust_dependencies(&project_path).await?;\n        \n        assert_eq!(deps.dependencies.len(), 3);\n        assert_eq!(deps.dev_dependencies.len(), 1);\n        \n        let serde_dep = deps.dependencies.iter().find(|d| d.name == \"serde\").unwrap();\n        assert_eq!(serde_dep.version, \"1.0\");\n        assert!(matches!(serde_dep.source, DependencySource::Registry));\n        \n        let local_dep = deps.dependencies.iter().find(|d| d.name == \"local-dep\").unwrap();\n        assert!(matches!(local_dep.source, DependencySource::Path { .. }));\n        \n        Ok(())\n    }\n}","structuredPatch":[{"oldStart":377,"oldLines":29,"newStart":377,"newLines":86,"lines":["     fn default() -> Self {","         let mut allowed_dirs = Vec::new();","         ","-        // Add user's home directory subdirectories","+        // Add user's home directory subdirectories with validation","         if let Some(home) = dirs::home_dir() {","-            allowed_dirs.push(home.join(\"Documents\"));","-            allowed_dirs.push(home.join(\"Projects\"));","-            allowed_dirs.push(home.join(\"workspace\"));","-            allowed_dirs.push(home.join(\"dev\"));","-            allowed_dirs.push(home.join(\"src\"));","-            allowed_dirs.push(home.join(\"Desktop\"));","+            // List of subdirectories to allow under home","+            let subdirs = [","+                \"Documents\",","+                \"Projects\", ","+                \"workspace\",","+                \"dev\",","+                \"src\",","+                \"Desktop\",","+                \"GitHub\",","+                \"repos\",","+                \"code\",","+            ];","+            ","+            for subdir in &subdirs {","+                let path = home.join(subdir);","+                // Only add if directory exists and can be canonicalized","+                if path.exists() && path.is_dir() {","+                    if let Ok(canonical) = path.canonicalize() {","+                        // Verify it's still under home after canonicalization (no symlink escape)","+                        if let Ok(canonical_home) = home.canonicalize() {","+                            if canonical.starts_with(&canonical_home) {","+                                allowed_dirs.push(canonical);","+                            }","+                        }","+                    }","+                }","+            }","         }","         ","-        // Add current working directory if not in system location","+        // Add current working directory if safe","         if let Ok(cwd) = std::env::current_dir() {","-            let cwd_str = cwd.to_string_lossy().to_lowercase();","-            #[cfg(target_os = \"windows\")]","-            let is_system = cwd_str.starts_with(\"c:\\\\windows\") || cwd_str.starts_with(\"c:\\\\program\");","-            #[cfg(not(target_os = \"windows\"))]","-            let is_system = cwd_str.starts_with(\"/etc\") || cwd_str.starts_with(\"/sys\");","-            ","-            if !is_system {","-                allowed_dirs.push(cwd);","+            if let Ok(canonical_cwd) = cwd.canonicalize() {","+                let cwd_str = canonical_cwd.to_string_lossy().to_lowercase();","+                ","+                // Block system directories across all platforms","+                let is_system = ","+                    // Windows system directories","+                    cwd_str.starts_with(\"c:\\\\windows\") || ","+                    cwd_str.starts_with(\"c:\\\\program files\") ||","+                    cwd_str.starts_with(\"c:\\\\programdata\") ||","+                    // Unix/Linux system directories","+                    cwd_str.starts_with(\"/etc\") || ","+                    cwd_str.starts_with(\"/sys\") ||","+                    cwd_str.starts_with(\"/proc\") ||","+                    cwd_str.starts_with(\"/dev\") ||","+                    cwd_str.starts_with(\"/boot\") ||","+                    cwd_str.starts_with(\"/bin\") ||","+                    cwd_str.starts_with(\"/sbin\") ||","+                    cwd_str.starts_with(\"/lib\") ||","+                    cwd_str.starts_with(\"/usr/bin\") ||","+                    cwd_str.starts_with(\"/usr/sbin\") ||","+                    // macOS system directories","+                    cwd_str.starts_with(\"/system\") ||","+                    cwd_str.starts_with(\"/library\") ||","+                    cwd_str.starts_with(\"/private\");","+                ","+                if !is_system {","+                    allowed_dirs.push(canonical_cwd);","+                }","             }","         }","         ","+        // Add temp directory for scratch projects (sandboxed)","+        if let Some(temp_dir) = dirs::data_local_dir() {","+            let atom_temp = temp_dir.join(\"atom-ide\").join(\"projects\");","+            // Create if doesn't exist","+            if !atom_temp.exists() {","+                let _ = std::fs::create_dir_all(&atom_temp);","+            }","+            if let Ok(canonical) = atom_temp.canonicalize() {","+                allowed_dirs.push(canonical);","+            }","+        }","+        ","+        // Remove duplicates and sort","+        allowed_dirs.sort();","+        allowed_dirs.dedup();","+        ","         Self {","             allowed_directories: allowed_dirs,","             max_project_size: 10 * 1024 * 1024 * 1024, // 10GB"]}],"userModified":false,"replaceAll":false}}